linear_block:
  batch_norm: true
  layer_norm: false
  dropout: 0.1
  activation: true
  bias: true
  out_dim: 128
  in_dim: 128
