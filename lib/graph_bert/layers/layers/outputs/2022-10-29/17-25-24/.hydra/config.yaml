linear_layer:
  batch_norm: true
  layer_norm: false
  dropout: 0.1
  activation: true
  bias: true
  out_dim: 128
  in_dim: 128
norm_layer:
  in_dim: 128
output_attention:
  batch_norm: true
  layer_norm: false
  dropout: 0.1
  activation: true
  bias: true
  out_dim: 128
  in_dim: 128
readout:
  readout: MEAN
